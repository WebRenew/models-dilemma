-- Create AI Models table to store available models from AI Gateway
CREATE TABLE IF NOT EXISTS ai_models (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  model_id TEXT UNIQUE NOT NULL,
  provider TEXT NOT NULL,
  description TEXT,
  input_price_per_million DECIMAL(10, 4) NOT NULL,
  output_price_per_million DECIMAL(10, 4) NOT NULL,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Create index for faster lookups by provider
CREATE INDEX IF NOT EXISTS idx_ai_models_provider ON ai_models(provider);

-- Create index for faster lookups by model_id
CREATE INDEX IF NOT EXISTS idx_ai_models_model_id ON ai_models(model_id);

-- Seed the models data
INSERT INTO ai_models (model_id, provider, description, input_price_per_million, output_price_per_million) VALUES
('alibaba/qwen-3-14b', 'alibaba', 'Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.', 0.0600, 0.2400),
('alibaba/qwen-3-235b', 'alibaba', 'Qwen3-235B-A22B-Instruct-2507 is the updated version of the Qwen3-235B-A22B non-thinking mode.', 0.1300, 0.6000),
('alibaba/qwen-3-30b', 'alibaba', 'Qwen3 is the latest generation of large language models in Qwen series.', 0.0800, 0.2900),
('alibaba/qwen-3-32b', 'alibaba', 'Qwen3 is the latest generation of large language models in Qwen series.', 0.1000, 0.3000),
('alibaba/qwen3-235b-a22b-thinking', 'alibaba', 'Qwen3-235B-A22B-Thinking-2507 scaling the thinking capability of Qwen3-235B-A22B.', 0.3000, 2.9000),
('alibaba/qwen3-coder', 'alibaba', 'Mixture-of-experts LLM with advanced coding and reasoning capabilities.', 0.3800, 1.5300),
('alibaba/qwen3-coder-30b-a3b', 'alibaba', 'Efficient coding specialist balancing performance with cost-effectiveness.', 0.0700, 0.2700),
('alibaba/qwen3-coder-plus', 'alibaba', 'Powerful Coding Agent that excels in tool calling and environment interaction.', 1.0000, 5.0000),
('alibaba/qwen3-max', 'alibaba', 'Qwen 3 series Max model with specialized upgrades in agent programming and tool invocation.', 1.2000, 6.0000),
('alibaba/qwen3-max-preview', 'alibaba', 'Qwen3-Max-Preview shows substantial gains over the 2.5 series in overall capability.', 1.2000, 6.0000),
('alibaba/qwen3-next-80b-a3b-instruct', 'alibaba', 'Qwen3-Next uses a highly sparse MoE design: 80B total parameters, ~3B activated per inference.', 0.1500, 1.5000),
('alibaba/qwen3-next-80b-a3b-thinking', 'alibaba', 'Qwen3-Next-80B-A3B-Thinking excels at complex reasoning tasks.', 0.1500, 1.5000),
('alibaba/qwen3-vl-instruct', 'alibaba', 'Qwen3 series VL models with enhanced visual coding and spatial perception.', 0.7000, 2.8000),
('alibaba/qwen3-vl-thinking', 'alibaba', 'Qwen3 series VL models with enhanced multimodal reasoning capabilities.', 0.7000, 8.4000),
('amazon/nova-lite', 'amazon', 'A very low cost multimodal model that is lightning fast.', 0.0600, 0.2400),
('amazon/nova-micro', 'amazon', 'A text-only model that delivers the lowest latency responses at very low cost.', 0.0350, 0.1400),
('amazon/nova-pro', 'amazon', 'A highly capable multimodal model with best combination of accuracy, speed, and cost.', 0.8000, 3.2000),
('anthropic/claude-3-haiku', 'anthropic', 'Anthropic fastest model designed for enterprise workloads.', 0.2500, 1.2500),
('anthropic/claude-3-opus', 'anthropic', 'Anthropic most intelligent model with best-in-market performance on highly complex tasks.', 15.0000, 75.0000),
('anthropic/claude-3.5-haiku', 'anthropic', 'Next generation of the fastest Claude model.', 0.8000, 4.0000),
('anthropic/claude-3.5-sonnet', 'anthropic', 'State-of-the-art for software engineering and agentic capabilities.', 3.0000, 15.0000),
('anthropic/claude-3.5-sonnet-20240620', 'anthropic', 'Claude 3.5 Sonnet raises the industry bar for intelligence.', 3.0000, 15.0000),
('anthropic/claude-3.7-sonnet', 'anthropic', 'First hybrid reasoning model and Anthropic most intelligent model to date.', 3.0000, 15.0000),
('anthropic/claude-haiku-4.5', 'anthropic', 'Matches Sonnet 4 performance on coding at substantially lower cost.', 1.0000, 5.0000),
('anthropic/claude-opus-4', 'anthropic', 'Anthropic most powerful model and best coding model in the world.', 15.0000, 75.0000),
('anthropic/claude-opus-4.1', 'anthropic', 'Drop-in replacement for Opus 4 with superior performance.', 15.0000, 75.0000),
('anthropic/claude-opus-4.5', 'anthropic', 'Latest model in Opus series for demanding reasoning tasks.', 5.0000, 25.0000),
('anthropic/claude-sonnet-4', 'anthropic', 'Improves on Sonnet 3.7 capabilities, excelling in coding.', 3.0000, 15.0000),
('anthropic/claude-sonnet-4.5', 'anthropic', 'Newest model in the Sonnet series with improvements over Sonnet 4.', 3.0000, 15.0000),
('cohere/command-a', 'cohere', 'Cohere most performant model, excelling at tool use, agents, and RAG.', 2.5000, 10.0000),
('deepseek/deepseek-r1', 'deepseek', 'DeepSeek R1 model with minor version upgrade.', 0.5000, 2.1500),
('deepseek/deepseek-v3', 'deepseek', 'Fast general-purpose LLM with enhanced reasoning capabilities.', 0.7700, 0.7700),
('deepseek/deepseek-v3.1', 'deepseek', 'DeepSeek-V3.1 post-trained on DeepSeek-V3.1-Base with long context extension.', 0.3000, 1.0000),
('deepseek/deepseek-v3.1-terminus', 'deepseek', 'Delivers more stable and reliable outputs across benchmarks.', 0.2700, 1.0000),
('deepseek/deepseek-v3.2', 'deepseek', 'Official successor to V3.2-Exp.', 0.2800, 0.4200),
('deepseek/deepseek-v3.2-exp', 'deepseek', 'Experimental model with DeepSeek Sparse Attention mechanism.', 0.2700, 0.4000),
('deepseek/deepseek-v3.2-speciale', 'deepseek', 'Pushing the boundaries of reasoning capabilities (thinking mode only).', 0.2800, 0.4200),
('deepseek/deepseek-v3.2-thinking', 'deepseek', 'Thinking mode of DeepSeek V3.2.', 0.2800, 0.4200),
('google/gemini-2.0-flash', 'google', 'Next-gen features with superior speed and native tool use.', 0.1000, 0.4000),
('google/gemini-2.0-flash-lite', 'google', 'Speed, built-in tool use, multimodal generation, and 1M token context.', 0.0750, 0.3000),
('google/gemini-2.5-flash', 'google', 'Thinking model offering balance between price and performance.', 0.3000, 2.5000),
('google/gemini-2.5-flash-image', 'google', 'First fully hybrid reasoning model for creative workflows.', 0.3000, 2.5000),
('google/gemini-2.5-flash-image-preview', 'google', 'Preview of hybrid reasoning model for creative workflows.', 0.3000, 2.5000),
('google/gemini-2.5-flash-lite', 'google', 'Balanced, low-latency model with configurable thinking budgets.', 0.1000, 0.4000),
('google/gemini-2.5-flash-lite-preview-09-2025', 'google', 'Preview of Flash-Lite model.', 0.1000, 0.4000),
('google/gemini-2.5-flash-preview-09-2025', 'google', 'Preview of Gemini 2.5 Flash.', 0.3000, 2.5000),
('google/gemini-2.5-pro', 'google', 'Most advanced reasoning Gemini model for complex problems.', 1.2500, 10.0000),
('google/gemini-3-pro-image', 'google', 'Studio-quality visuals with unparalleled precision and control.', 2.0000, 120.0000),
('google/gemini-3-pro-preview', 'google', 'Improves upon Gemini 2.5 Pro for challenging tasks.', 2.0000, 12.0000),
('inception/mercury-coder-small', 'inception', 'Ideal for code generation, debugging, and refactoring with minimal latency.', 0.2500, 1.0000),
('meituan/longcat-flash-chat', 'meituan', 'High-throughput MoE chat model (128k context) for agentic tasks.', 0.0000, 0.0000),
('meituan/longcat-flash-thinking', 'meituan', 'High-throughput MoE reasoning model (128k context) for agentic tasks.', 0.1500, 1.5000),
('meta/llama-3.1-70b', 'meta', 'Update to Meta Llama 3 70B with 128K context and improved reasoning.', 0.7200, 0.7200),
('meta/llama-3.1-8b', 'meta', 'Llama 3.1 8B with 128K context, ideal for real-time conversational interfaces.', 0.0500, 0.0800),
('meta/llama-3.2-11b', 'meta', 'Instruction-tuned image reasoning generative model.', 0.1600, 0.1600),
('meta/llama-3.2-1b', 'meta', 'Text-only model for on-device use cases.', 0.1000, 0.1000),
('meta/llama-3.2-3b', 'meta', 'Text-only model for on-device use cases.', 0.1500, 0.1500),
('meta/llama-3.2-90b', 'meta', 'Instruction-tuned image reasoning generative model.', 0.7200, 0.7200),
('meta/llama-3.3-70b', 'meta', 'High-performance conversational AI for content creation and enterprise.', 0.7200, 0.7200),
('meta/llama-4-maverick', 'meta', 'Natively multimodal with 17B parameters and 128 experts.', 0.1500, 0.6000),
('meta/llama-4-scout', 'meta', 'Natively multimodal with 17B parameters and 16 experts.', 0.0800, 0.3000),
('minimax/minimax-m2', 'minimax', 'Compact MoE model built for elite performance in coding and agentic tasks.', 0.2700, 1.1500),
('mistral/codestral', 'mistral', 'Cutting-edge language model for coding, specializing in low-latency tasks.', 0.3000, 0.9000),
('mistral/devstral-small', 'mistral', 'Agentic LLM for software engineering tasks.', 0.1000, 0.3000),
('mistral/magistral-medium', 'mistral', 'Complex thinking with transparent reasoning you can follow and verify.', 2.0000, 5.0000),
('mistral/magistral-small', 'mistral', 'Complex thinking with high-fidelity reasoning across languages.', 0.5000, 1.5000),
('mistral/ministral-3b', 'mistral', 'Compact model for on-device tasks with low-latency performance.', 0.0400, 0.0400),
('mistral/ministral-8b', 'mistral', 'Powerful model with memory-efficient inference for edge applications.', 0.1000, 0.1000),
('mistral/mistral-large', 'mistral', 'Ideal for complex tasks requiring large reasoning capabilities.', 2.0000, 6.0000),
('mistral/mistral-medium', 'mistral', 'Frontier performance at significantly lower cost.', 0.4000, 2.0000),
('mistral/mistral-small', 'mistral', 'Ideal for simple tasks in bulk like Classification and Customer Support.', 0.1000, 0.3000),
('mistral/mixtral-8x22b-instruct', 'mistral', 'Mixture-of-experts open source model served by Fireworks.', 1.2000, 1.2000),
('mistral/pixtral-12b', 'mistral', '12B model with image understanding capabilities.', 0.1500, 0.1500),
('mistral/pixtral-large', 'mistral', 'Frontier-level image understanding for documents and charts.', 2.0000, 6.0000),
('moonshotai/kimi-k2', 'moonshotai', 'Large-scale MoE model with 1 trillion parameters, 32B active.', 0.5000, 2.0000),
('moonshotai/kimi-k2-0905', 'moonshotai', 'Strong performance on agentic tasks with tool calling and reasoning.', 0.6000, 2.5000),
('moonshotai/kimi-k2-thinking', 'moonshotai', 'Advanced thinking model executing up to 300 sequential tool calls.', 0.6000, 2.5000),
('moonshotai/kimi-k2-thinking-turbo', 'moonshotai', 'High-speed version of kimi-k2-thinking.', 1.1500, 8.0000),
('moonshotai/kimi-k2-turbo', 'moonshotai', 'High-speed version with 60 tokens/second output.', 2.4000, 10.0000),
('morph/morph-v3-fast', 'morph', 'Applies code changes at 4500+ tokens/second.', 0.8000, 1.2000),
('morph/morph-v3-large', 'morph', 'Applies code changes at 2500+ tokens/second.', 0.9000, 1.9000),
('openai/gpt-3.5-turbo', 'openai', 'Most capable GPT-3.5 model optimized for chat.', 0.5000, 1.5000),
('openai/gpt-3.5-turbo-instruct', 'openai', 'GPT-3 era capabilities with legacy Completions endpoint.', 1.5000, 2.0000),
('openai/gpt-4-turbo', 'openai', 'Broad general knowledge with 128K context window.', 10.0000, 30.0000),
('openai/gpt-4.1', 'openai', 'OpenAI flagship model for complex tasks.', 2.0000, 8.0000),
('openai/gpt-4.1-mini', 'openai', 'Balance between intelligence, speed, and cost.', 0.4000, 1.6000),
('openai/gpt-4.1-nano', 'openai', 'Fastest, most cost-effective GPT 4.1 model.', 0.1000, 0.4000),
('openai/gpt-4o', 'openai', 'Matches GPT-4 Turbo performance with faster and cheaper API.', 2.5000, 10.0000),
('openai/gpt-4o-mini', 'openai', 'Most advanced and cost-efficient small model.', 0.1500, 0.6000),
('openai/gpt-5', 'openai', 'Flagship language model for complex reasoning and agentic tasks.', 1.2500, 10.0000),
('openai/gpt-5-chat', 'openai', 'GPT-5 snapshot currently used in ChatGPT.', 1.2500, 10.0000),
('openai/gpt-5-codex', 'openai', 'GPT-5 optimized for agentic coding tasks.', 1.2500, 10.0000),
('openai/gpt-5-mini', 'openai', 'Cost optimized model for reasoning/chat tasks.', 0.2500, 2.0000),
('openai/gpt-5-nano', 'openai', 'High throughput model for simple instruction tasks.', 0.0500, 0.4000),
('openai/gpt-5-pro', 'openai', 'Uses more compute for consistently better answers.', 15.0000, 120.0000),
('openai/gpt-5.1-codex', 'openai', 'GPT-5.1 optimized for agentic coding tasks.', 1.2500, 10.0000),
('openai/gpt-5.1-codex-mini', 'openai', 'Smaller, faster, and cheaper version of GPT-5.1 Codex.', 0.2500, 2.0000),
('openai/gpt-5.1-instant', 'openai', 'Warmer and more conversational with adaptive reasoning.', 1.2500, 10.0000),
('openai/gpt-5.1-thinking', 'openai', 'Adapts thinking time based on question complexity.', 1.2500, 10.0000),
('openai/gpt-oss-120b', 'openai', 'Extremely capable LLM with controllable reasoning.', 0.1000, 0.5000),
('openai/gpt-oss-20b', 'openai', 'Compact open-weight model for low-latency deployments.', 0.0700, 0.3000),
('openai/gpt-oss-safeguard-20b', 'openai', 'First open weight reasoning model for safety classification.', 0.0750, 0.3000),
('openai/o1', 'openai', 'Flagship reasoning model for complex multi-step tasks.', 15.0000, 60.0000),
('openai/o3', 'openai', 'Most powerful reasoning model with state-of-the-art benchmarks.', 2.0000, 8.0000),
('openai/o3-deep-research', 'openai', 'Most advanced model for deep, multi-step research tasks.', 10.0000, 40.0000),
('openai/o3-mini', 'openai', 'Small reasoning model with high intelligence at low cost.', 1.1000, 4.4000),
('openai/o4-mini', 'openai', 'Fast, cost-efficient reasoning with exceptional performance.', 1.1000, 4.4000),
('perplexity/sonar', 'perplexity', 'Lightweight offering with search grounding.', 1.0000, 1.0000),
('perplexity/sonar-pro', 'perplexity', 'Premier offering with advanced queries and search grounding.', 3.0000, 15.0000),
('perplexity/sonar-reasoning', 'perplexity', 'Reasoning-focused model with Chain of Thought and search grounding.', 1.0000, 5.0000),
('perplexity/sonar-reasoning-pro', 'perplexity', 'Premium reasoning model with enhanced search capabilities.', 2.0000, 8.0000),
('prime-intellect/intellect-3', 'prime-intellect', 'INTELLECT-3: Scaling RL to 100B+ MoE model with SOTA performance.', 0.2000, 1.1000),
('stealth/sonoma-dusk-alpha', 'stealth', 'Powered by Grok 4 Fast Non-Reasoning with 2M token context.', 0.2000, 0.5000),
('stealth/sonoma-sky-alpha', 'stealth', 'Powered by Grok 4 Fast Reasoning with 2M token context.', 0.2000, 0.5000),
('vercel/v0-1.0-md', 'vercel', 'Model behind v0 for modern web apps.', 3.0000, 15.0000),
('vercel/v0-1.5-md', 'vercel', 'Model behind v0 for modern web apps.', 3.0000, 15.0000),
('xai/grok-2', 'xai', 'Frontier language model with state-of-the-art reasoning.', 2.0000, 10.0000),
('xai/grok-2-vision', 'xai', 'Vision model with state-of-the-art visual reasoning.', 2.0000, 10.0000),
('xai/grok-3', 'xai', 'Flagship model for enterprise use cases.', 3.0000, 15.0000),
('xai/grok-3-fast', 'xai', 'Flagship model on faster infrastructure.', 5.0000, 25.0000),
('xai/grok-3-mini', 'xai', 'Lightweight model that thinks before responding.', 0.3000, 0.5000),
('xai/grok-3-mini-fast', 'xai', 'Fast version of the lightweight thinking model.', 0.6000, 4.0000),
('xai/grok-4', 'xai', 'Latest flagship with unparalleled performance.', 3.0000, 15.0000),
('xai/grok-4-fast-non-reasoning', 'xai', 'Latest multimodal model with SOTA cost-efficiency.', 0.2000, 0.5000),
('xai/grok-4-fast-reasoning', 'xai', 'Latest multimodal model with reasoning enabled.', 0.2000, 0.5000),
('xai/grok-4.1-fast-non-reasoning', 'xai', 'Best tool-calling model optimized for speed.', 0.2000, 0.5000),
('xai/grok-4.1-fast-reasoning', 'xai', 'Best tool-calling model for maximal intelligence.', 0.2000, 0.5000),
('xai/grok-code-fast-1', 'xai', 'Latest coding model with 256K context.', 0.2000, 1.5000),
('zai/glm-4.5', 'zai', 'Foundation models for intelligent agents with 355B parameters.', 0.6000, 2.2000),
('zai/glm-4.5-air', 'zai', 'Streamlined MoE design with 106B total parameters.', 0.2000, 1.1000),
('zai/glm-4.5v', 'zai', 'VL model with enhanced visual understanding.', 0.6000, 1.8000),
('zai/glm-4.6', 'zai', 'Latest GLM with enhancements across multiple domains.', 0.4500, 1.8000)
ON CONFLICT (model_id) DO UPDATE SET
  provider = EXCLUDED.provider,
  description = EXCLUDED.description,
  input_price_per_million = EXCLUDED.input_price_per_million,
  output_price_per_million = EXCLUDED.output_price_per_million;
